# 2023.10.6

- æµ‹è¯•å¯¹è±¡ï¼škarate
- è¶…å‚æ•°ï¼š
  -  batch size = 128
  -  learning rate = 1e-3
  -  MAX_MEMORY_CAPACITY = 5000
  -  TAU = 0.005
  -  GAMMA = 0.9
  -  EPS_START = 0.9
  - EPS_END = 0.05
  - EPS_DECAY = 1000
- åˆå§‹ rumor node æ•°é‡/æ¯”ä¾‹ï¼š10%
- authoritative T node æ•°é‡/æ¯”ä¾‹ï¼š1 ä¸ª
- å¥–åŠ±å‡½æ•°ï¼š
    $$
    \text{reward} = e^{\frac{\text{new}|T|}{\text{last}|T|}-1}-(1.2\times|R|+e^{-1})
    $$
    
    æ€è·¯ï¼šå½“ T nodes çš„å¢é•¿å€ç‡è¶…è¿‡ 2 æ—¶ï¼Œæ‰æœ‰å¯èƒ½å¾—åˆ°æ­£çš„å¥–åŠ±ï¼Œå¦åˆ™å¥–åŠ±å‡ä¸ºè´Ÿå€¼


è®­ç»ƒç»“æœï¼š

![](result_img/test_karate_rewardFunc-v1.jpg)

ä¸€å…±è·‘äº† 20000æ¬¡ episodeï¼›loss å¾ˆå¤§ï¼›å¹³å‡ R active nodes ç¨³å®šåœ¨ 8.45 é™„è¿‘ï¼›å®é™…ä¸Šåœ¨ 8000 æ¬¡ episode å°±å·²ç»æ¯”è¾ƒç¨³å®šã€‚

å®éªŒäº†ä¸€ä¸‹ï¼Œæ•ˆæœå¾ˆå·®. è·Ÿè®­ç»ƒç»“æœæ¥è¿‘ï¼Œæˆ–è€…éƒ½æ²¡è¾¾åˆ°ï¼ˆğŸ˜­ğŸ˜­ï¼‰

å‚æ•°ï¼šau_T_rate=0.06; r_rate=0.1; T_rate_min=0.1; T_rate_max=0.25; iters=500

|         | 0.1   | 0.11666667 | 0.13333333 | 0.15   | 0.16666667 | 0.18333333 | 0.2    | 0.21666667 | 0.23333333 | 0.25   |
| ------- | ----- | ---------- | ---------- | ------ | ---------- | ---------- | ------ | ---------- | ---------- | ------ |
| R nodes | 9.346 | 9.76       | 9.542      | 9.218  | 8.96       | 9.85       | 9.87   | 9.566      | 9.246      | 9.408  |
| T nodes | 11.84 | 11.862     | 12.594     | 13.592 | 13.634     | 13.548     | 13.236 | 13.132     | 13.838     | 13.844 |

æƒ³è¦è¶…è¿‡ `contrid` ç®—æ³•ï¼Œè‡³å°‘ $\frac{T}{R}\ge 1.71$; è¶…è¿‡ `M3T` ç®—æ³•ï¼Œè‡³å°‘ $\frac{T}{R}\ge 2.39$


**æ”¹è¿›æ€è·¯ï¼š** 
1. ä¿®æ”¹å¥–åŠ±å‡½æ•°ï¼Œæé«˜ T node çš„å¥–åŠ±
2. ä¿®æ”¹ envï¼Œåœ¨æ¯æ¬¡ step ä¹‹åï¼Œå¯ä»¥é€‰æ‹©æ–°å˜æˆ R-active node çš„ç‚¹ä½œä¸º action


# 2023.10.7

- æµ‹è¯•å¯¹è±¡ï¼škarate
- è¶…å‚æ•°ï¼š
  -  batch size = 128
  -  learning rate = 1e-3
  -  MAX_MEMORY_CAPACITY = 5000
  -  TAU = 0.005
  -  GAMMA = 0.9
  -  EPS_START = 0.9
  - EPS_END = 0.05
  - EPS_DECAY = 1000
- åˆå§‹ rumor node æ•°é‡/æ¯”ä¾‹ï¼š10%
- authoritative T node æ•°é‡/æ¯”ä¾‹ï¼š1 ä¸ª
- å¥–åŠ±å‡½æ•°ï¼š
  $$
  \begin{cases}
  \ln(\frac{T}{R}), &\frac{T}{R}<1\\
  e^{\frac{T}{R}}, &else
  \end{cases}
  $$

  æ€è·¯ï¼šæ”¾å¤§ $\frac{T}{R}$ è¯´å¸¦æ¥çš„æ”¶ç›Š/æƒ©ç½š


è®­ç»ƒç»“æœï¼š

![](result_img/test_karate_rewardFunc-v2.jpg)

ç»è¿‡ 80000 æ¬¡ episode åï¼Œ$\frac{T}{R} \approx 4.804$ï¼›loss ä¾æ—§å¾ˆå¤§ã€‚

æ„Ÿè§‰è¿˜ä¸é”™ï¼Ÿå¯æƒœæ˜¯é”™è§‰ï¼ŒåŸºæœ¬æ²¡ä»€ä¹ˆå¤§çš„æ”¹å˜ã€‚ğŸ˜­ğŸ¤¡

|         | 0.1    | 0.11666667 | 0.13333333 | 0.15   | 0.16666667 | 0.18333333 | 0.2   | 0.21666667 | 0.23333333 | 0.25   |
| ------- | ------ | ---------- | ---------- | ------ | ---------- | ---------- | ----- | ---------- | ---------- | ------ |
| R nodes | 9.946  | 9.23       | 9.822      | 9.432  | 10.17      | 9.532      | 10.17 | 9.264      | 9.436      | 8.79   |
| T nodes | 11.432 | 12.198     | 12.132     | 12.624 | 12.642     | 13.262     | 12.79 | 13.608     | 13.578     | 14.262 |


è¿™ç»“æœå€’æ˜¯å’Œä¹‹å‰æŸæ¬¡çš„è®­ç»ƒç»“æœç±»ä¼¼

![](result_img/karate_test_1.jpg)

R active nodes çš„æ•°é‡åœ¨ 10 ä¸ªå·¦å³å¾˜å¾Šã€‚


**æ”¹è¿›æ€è·¯ï¼š**
1. å¯¹ reward è¿›è¡Œè£å‰ªï¼Œå› ä¸º loss ä¾æ—§å¾ˆå·¨å¤§
2. æ¢ç´¢æ–°çš„ reward å‡½æ•°
3. æˆ–è®¸ experience pool å¤ªå°äº†ï¼Ÿå¢å¤§è¯•è¯•
4. å·©å›ºä¸€ä¸‹ç†è®ºå§


# 2023.10.8

**å»¶è¿Ÿå¥–åŠ±ï¼š**
> æ²¡æœ‰æ ‡ç­¾æ¥è¯´æ˜ç°åœ¨è¿™ä¸ª action æ˜¯æ­£ç¡®è¿˜æ˜¯é”™è¯¯çš„ï¼Œå¿…é¡»ç­‰åˆ°æ¸¸æˆç»“æŸæ‰å¯èƒ½çŸ¥é“ï¼Œè¿™ä¸ªæ¸¸æˆå¯èƒ½ 10s åæ‰ç»“æŸã€‚ç°åœ¨è¿™ä¸ªåŠ¨ä½œåˆ°åº•å¯¹æœ€åæ¸¸æˆæ˜¯å¦èƒ½èµ¢æœ‰æ— å¸®åŠ©ï¼Œæˆ‘ä»¬å…¶å®æ˜¯ä¸æ¸…æ¥šçš„ã€‚è¿™é‡Œæˆ‘ä»¬å°±é¢ä¸´å»¶è¿Ÿå¥–åŠ±ï¼ˆdelayed rewardï¼‰çš„é—®é¢˜ï¼Œå»¶è¿Ÿå¥–åŠ±ä½¿å¾—è®­ç»ƒç½‘ç»œéå¸¸å›°éš¾ã€‚

å¼ºåŒ–å­¦ä¹ ç‰¹å¾ï¼š
> 1. å¼ºåŒ–å­¦ä¹ ä¼šè¯•é”™æ¢ç´¢ï¼Œå®ƒé€šè¿‡æ¢ç´¢ç¯å¢ƒæ¥è·å–å¯¹ç¯å¢ƒçš„ç†è§£ã€‚
> 2. å¼ºåŒ–å­¦ä¹ æ™ºèƒ½ä½“ä¼šä»ç¯å¢ƒé‡Œé¢è·å¾—å»¶è¿Ÿçš„å¥–åŠ±ã€‚
> 3. åœ¨å¼ºåŒ–å­¦ä¹ çš„è®­ç»ƒè¿‡ç¨‹ä¸­ï¼Œ**æ—¶é—´éå¸¸é‡è¦**ã€‚å› ä¸ºæˆ‘ä»¬å¾—åˆ°çš„æ˜¯æœ‰æ—¶é—´å…³è”çš„æ•°æ®ï¼ˆsequential dataï¼‰ï¼Œ è€Œä¸æ˜¯ç‹¬ç«‹åŒåˆ†å¸ƒçš„æ•°æ®ã€‚åœ¨æœºå™¨å­¦ä¹ ä¸­ï¼Œå¦‚æœè§‚æµ‹æ•°æ®æœ‰éå¸¸å¼ºçš„å…³è”ï¼Œä¼šä½¿å¾—è®­ç»ƒéå¸¸ä¸ç¨³å®šã€‚è¿™ä¹Ÿæ˜¯ä¸ºä»€ä¹ˆåœ¨ç›‘ç£å­¦ä¹ ä¸­ï¼Œæˆ‘ä»¬å¸Œæœ›æ•°æ®å°½é‡æ»¡è¶³ç‹¬ç«‹åŒåˆ†å¸ƒï¼Œè¿™æ ·å°±å¯ä»¥æ¶ˆé™¤æ•°æ®ä¹‹é—´çš„ç›¸å…³æ€§ã€‚
> 4. æ™ºèƒ½ä½“çš„åŠ¨ä½œä¼šå½±å“å®ƒéšåå¾—åˆ°çš„æ•°æ®ï¼Œè¿™ä¸€ç‚¹æ˜¯éå¸¸é‡è¦çš„ã€‚åœ¨è®­ç»ƒæ™ºèƒ½ä½“çš„è¿‡ç¨‹ä¸­ï¼Œå¾ˆå¤šæ—¶ å€™æˆ‘ä»¬ä¹Ÿæ˜¯é€šè¿‡æ­£åœ¨å­¦ä¹ çš„æ™ºèƒ½ä½“ä¸ç¯å¢ƒäº¤äº’æ¥å¾—åˆ°æ•°æ®çš„ã€‚æ‰€ä»¥å¦‚æœåœ¨è®­ç»ƒè¿‡ç¨‹ä¸­ï¼Œæ™ºèƒ½ä½“ä¸èƒ½ä¿æŒç¨³å®šï¼Œå°±ä¼šä½¿æˆ‘ä»¬é‡‡é›†åˆ°çš„æ•°æ®éå¸¸ç³Ÿç³•ã€‚æˆ‘ä»¬é€šè¿‡æ•°æ®æ¥è®­ç»ƒæ™ºèƒ½ä½“ï¼Œå¦‚æœæ•°æ®æœ‰é—®é¢˜ï¼Œæ•´ä¸ªè®­ç»ƒè¿‡ç¨‹å°±ä¼šå¤±è´¥ã€‚æ‰€ä»¥åœ¨å¼ºåŒ–å­¦ä¹ é‡Œé¢ä¸€ä¸ªéå¸¸é‡è¦çš„é—®é¢˜å°±æ˜¯ï¼Œ**æ€ä¹ˆè®©æ™ºèƒ½ä½“çš„åŠ¨ä½œä¸€ç›´ç¨³å®šåœ°æå‡**ã€‚



**rolloutï¼ˆé¢„æ¼”ï¼‰**
> é¢„æ¼”æ˜¯æŒ‡ä»å½“å‰ç¯å¢ƒå¯¹åŠ¨ä½œè¿›è¡Œé‡‡æ ·ï¼Œç”Ÿæˆå¾ˆå¤šå±€æ¸¸æˆã€‚å°†å½“å‰çš„æ™ºèƒ½ä½“ä¸ç¯å¢ƒäº¤äº’ï¼Œä¼šå¾—åˆ°ä¸€ç³»åˆ—è§‚æµ‹ã€‚æ¯ä¸€ä¸ªè§‚æµ‹å¯çœ‹æˆä¸€ä¸ª**è½¨è¿¹(trajectory)**ï¼Œå³ state å’Œ action çš„åºåˆ—ï¼š
> $$\tau=(s_0,a_0,s_1,a_1,...)$$
>
> æˆ‘ä»¬å¯ä»¥é€šè¿‡è§‚æµ‹åºåˆ—ä»¥åŠæœ€ç»ˆå¥–åŠ±(eventual reward)æ¥è®­ç»ƒ agentï¼Œä½¿å®ƒå°½å¯èƒ½çš„é‡‡å–å¯ä»¥è·å¾—æœ€ç»ˆå¥–åŠ±çš„åŠ¨ä½œã€‚



**æ–°æƒ³æ³•**ï¼š
> ç›®å‰çš„ action ä¼¼ä¹æœ‰ç‚¹å¤šï¼Œä¸”è¡¨ç¤ºçš„æ„ä¹‰æ¯”è¾ƒæ¨¡ç³Šã€‚ç°åœ¨å‡å°‘ action çš„ä¸ªæ•°ï¼Œæ¯”å¦‚åœ¨æŸä¸ª state S1ï¼Œé‡‡ç”¨é€‰å–å½“å‰åº¦æœ€å¤§çš„ç‚¹ä½œä¸ºactionï¼›è¿›å…¥åˆ°ä¸‹ä¸€ä¸ª state S2, é‡‡ç”¨ M3T ç­–ç•¥ç­‰ã€‚ä¼¼ä¹æœ‰æå¤´ï¼ŸğŸ˜ˆ


# 2023.10.9
æ ¹æ®æ˜¨å¤©çš„æƒ³æ³•ï¼Œpolicy gradient çš„æ–¹æ³•åº”è¯¥æ›´é€‚åˆï¼Œæ¯”å¦‚é€‰ç”¨ PPOã€‚ä¸è¿‡å…ˆè¯•è¯• DQN çœ‹çœ‹æ•ˆæœå¦‚ä½•ã€‚

æ›´æ–°äº† envã€‚å…·ä½“é…ç½®å¦‚ä¸‹ï¼š

- æµ‹è¯•å¯¹è±¡ï¼škarate
- è¶…å‚æ•°ï¼š
  -  batch size = 128
  -  learning rate = 1e-3
  -  MAX_MEMORY_CAPACITY = 25000
  -  TAU = 0.005
  -  GAMMA = 0.9
  -  EPS_START = 0.9
  - EPS_END = 0.05
  - EPS_DECAY = 1000
- åˆå§‹ rumor node æ•°é‡/æ¯”ä¾‹ï¼š10%
- authoritative T node æ•°é‡/æ¯”ä¾‹ï¼š1 ä¸ª
- select T nodes çš„æ•°é‡: 3 ä¸ª
- å¥–åŠ±å‡½æ•°ï¼š
    $$
    \text{reward} =
    \begin{cases}
    |T|-|R|, &\text{terminated or truncated}\\
    0, &\text{else}
    \end{cases}
    $$
    æ€è·¯ï¼šæœ´ç´ æ— åï¼Œå»¶è¿Ÿå¥–åŠ±ï¼Œåªæœ‰ç»“æŸæ—¶æ‰æœ‰ rewardï¼Œå¦åˆ™ä¸º 0

æœ¬æ¬¡é‡ç‚¹å¯¹ç¯å¢ƒè¿›è¡Œäº†æ›´æ–°ï¼Œå°† action å‡å°‘ä¸º 3 ä¸ªï¼Œå…·ä½“å¦‚ä¸‹:
```python
self.action_space = spaces.Discrete(3)
self._action_to_algorithm = {
    0:self._action_degree_based,
    1:self._action_M3T_based,
    2:self._action_random_based
}
```
3 ä¸ª action åˆ†åˆ«å¯¹åº”äº† `degree`,`M3T`,`random` ä¸‰ç§ç®—æ³•

è®­ç»ƒç»“æœå›¾å¦‚ä¸‹ï¼š

![](result_img/test_karate_newAction-v1_k=3.jpg)

- loss ç¨³å®šä¸‹é™ï¼Œå¹¶ä¸”è¿˜æœ‰ä¸‹é™ç©ºé—´
- å‰ 10000 æ¬¡ episode å¾—åˆ†å˜åŒ–ä¸å¤§ï¼Œä¹‹åæœ‰ä¸€ä¸ªæ˜æ˜¾çš„ä¸Šç”Ÿè¶‹åŠ¿

average score ä» 3.10145 å‡è‡³ 3.18 åå·¦å³æ³¢åŠ¨äº†å¾ˆé•¿ä¸€æ®µæ—¶é—´ï¼Œä¹‹åç¨³å®šä¸Šå‡è‡³ 3.7723

å®é™…è¯•éªŒä¸€ä¸‹ï¼š

|         | 0.1   | 0.11666667 | 0.13333333 | 0.15   | 0.16666667 | 0.18333333 | 0.2    | 0.21666667 | 0.23333333 | 0.25   |
| ------- | ----- | ---------- | ---------- | ------ | ---------- | ---------- | ------ | ---------- | ---------- | ------ |
| R nodes | 7.56  | 7.7        | 7.164      | 7.272  | 7.434      | 6.576      | 6.9    | 6.67       | 6.622      | 6.082  |
| T nodes | 19.51 | 19.238     | 20.672     | 21.552 | 21.498     | 22.958     | 22.916 | 23.676     | 23.44      | 24.436 |

æ•ˆæœå¥½å¤šäº† ğŸ˜ğŸ‘

`contrid` çš„ç»“æœï¼š
|         | 0.1   | 0.11666667 | 0.13333333 | 0.15   | 0.16666667 | 0.18333333 | 0.2    | 0.21666667 | 0.23333333 | 0.25   |
| ------- | ----- | ---------- | ---------- | ------ | ---------- | ---------- | ------ | ---------- | ---------- | ------ |
| R nodes | 8.162 | 8.304      | 7.662      | 7.29   | 7.636      | 7.156      | 7.336  | 7.592      | 7.332      | 7.056  |
| T nodes | 14.4  | 14.548     | 15.954     | 17.354 | 16.644     | 17.846     | 17.884 | 18.552     | 18.422     | 19.506 |

`M3T` çš„ç»“æœï¼š
|         | 0.1    | 0.11666667 | 0.13333333 | 0.15   | 0.16666667 | 0.18333333 | 0.2    | 0.21666667 | 0.23333333 | 0.25  |
| ------- | ------ | ---------- | ---------- | ------ | ---------- | ---------- | ------ | ---------- | ---------- | ----- |
| R nodes | 6.988  | 7.026      | 6.432      | 5.79   | 5.572      | 5.69       | 5.482  | 5.236      | 5.458      | 5.394 |
| T nodes | 18.008 | 17.506     | 19.906     | 22.518 | 22.698     | 24.228     | 24.306 | 25.716     | 25.688     | 26.6  |

æ•ˆæœå·²ç»æ˜¯è¶…è¿‡ `contrid` ï¼Œä½†ä¸ `M3T` è¿˜æ˜¯æœ‰ç‚¹å·®è·


# 2023.10.10

- æµ‹è¯•å¯¹è±¡ï¼škarate
- è¶…å‚æ•°ï¼š
  -  batch size = 128
  -  learning rate = 1e-3
  -  MAX_MEMORY_CAPACITY = 25000
  -  TAU = 0.005
  -  GAMMA = 0.9
  -  EPS_START = 0.9
  - EPS_END = 0.05
  - EPS_DECAY = 1000
- åˆå§‹ rumor node æ•°é‡/æ¯”ä¾‹ï¼š10%
- authoritative T node æ•°é‡/æ¯”ä¾‹ï¼š1 ä¸ª
- select T nodes çš„æ•°é‡: 10 ä¸ª
- å¥–åŠ±å‡½æ•°ï¼š
    $$
    \text{reward} =
    \begin{cases}
    |T|-|R|, &\text{terminated or truncated}\\
    0, &\text{else}
    \end{cases}
    $$

ç°åœ¨å°† select T nodes çš„æ•°é‡æå‡åˆ° 10 ä¸ªï¼Œæ¥è¿‘karateç½‘ç»œ $\frac{1}{3}$ çš„èŠ‚ç‚¹æ•°ã€‚

è®­ç»ƒç»“æœ

![](result_img/test_karate_newAction-v1_k=10.jpg)

- 20000 æ¬¡ episode çš„ average score ä¸º 5.7983, æœ‰ç¼“æ…¢ä¸Šå‡çš„è¶‹åŠ¿ï¼›loss ä¸º 3.4507ï¼Œ ä¹Ÿæœ‰é€æ¸å‡å°çš„è¶‹åŠ¿ã€‚
- æ€»ä½“è€Œè¨€æ²¡ä»€ä¹ˆå¤§çš„å˜åŒ–è¶‹åŠ¿

æµ‹è¯•æ•ˆæœï¼š
|         | 0.1    | 0.11666667 | 0.13333333 | 0.15   | 0.16666667 | 0.18333333 | 0.2    | 0.21666667 | 0.23333333 | 0.25   |
| ------- | ------ | ---------- | ---------- | ------ | ---------- | ---------- | ------ | ---------- | ---------- | ------ |
| R nodes | 9.42   | 9.436      | 8.522      | 7.97   | 7.924      | 7.432      | 7.108  | 6.666      | 7.096      | 6.3    |
| T nodes | 13.554 | 13.068     | 15.324     | 18.122 | 18.326     | 20.142     | 20.442 | 22.158     | 21.658     | 23.138 |

å®é™…æ•ˆæœæ›´å·®äº†ã€‚

`degree` çš„ç»“æœï¼š
|         | 0.1    | 0.11666667 | 0.13333333 | 0.15   | 0.16666667 | 0.18333333 | 0.2    | 0.21666667 | 0.23333333 | 0.25   |
| ------- | ------ | ---------- | ---------- | ------ | ---------- | ---------- | ------ | ---------- | ---------- | ------ |
| R nodes | 7.746  | 7.9        | 7.07       | 7.348  | 7.09       | 6.782      | 6.692  | 6.83       | 6.578      | 6.564  |
| T nodes | 19.626 | 19.436     | 21.474     | 22.032 | 22.476     | 23.352     | 23.254 | 23.882     | 24.082     | 24.672 |

å®é™…ä¸Šä¹‹å‰çš„ `k=3` çš„ç½‘ç»œæœ€ç»ˆçš„é€‰æ‹©æ•ˆæœï¼Œä¸ `degree` æ˜¯æ¥è¿‘çš„ã€‚

**é—®é¢˜ï¼š** 
1. é€šè¿‡dqnç½‘ç»œè¿›è¡Œé€‰æ‹©ï¼Œå’Œéšæœºé€‰æ‹©è¿™ 3 ä¸ª algorithm æ¥é€‰å– nodeï¼Œæ˜¯å¦æœ‰åŒºåˆ«ï¼Ÿ
2. æ›´æ”¹ `select_k_Tnodes` è¿™ä¸ªå‚æ•°ï¼Œæ˜¯å¦å¯¹è®­ç»ƒç»“æœæœ‰å½±å“ï¼Ÿæ˜¯å¦å­˜åœ¨ä¸€ä¸ªæœ€ä¼˜çš„ `k` å€¼ï¼Ÿ


# 2023.10.11

æµ‹è¯•å¯¹è±¡åŒ `2023.10.10`.

**æ¢ç©¶é—®é¢˜**ï¼šä¸åŒ k å€¼æ˜¯å¦ä¼šå½±å“æµ‹è¯•ç»“æœ
- `select_k_Tnodes=1`: åœ¨æ¥è¿‘ 20000 æ¬¡ episodeæ—¶ï¼Œå¾—åˆ†å‡ºç°ä¸‹é™ï¼Œloss ä¹Ÿå¤§å¹…æå‡ï¼›ä¹‹å 20000~40000 æ¬¡ episode æ—¶ï¼Œå¾—åˆ†é€æ¸ä¸Šæ¶¨ï¼Œç¨³å®šåœ¨ 1.79 é™„è¿‘ã€‚
  ![](result_img/test_karate_newAction-v1_k=1.jpg)
- `select_k_Tnodes=3`: ä¹‹å‰è®­ç»ƒçš„ç»“æœå›¾,å¾—åˆ† 3.77 é™„è¿‘ã€‚
  ![](result_img/test_karate_newAction-v1_k=3.jpg)
- `select_k_Tnodes=5`:å®é™…ä¸Š20000å¤šæ¬¡åï¼Œå¾—åˆ†å°±åœ¨ 4.87 é™„è¿‘å°å¹…å˜åŒ–ã€‚
  ![](result_img/test_karate_newAction-v1_k=5.jpg)
- `select_k_Tnodes=7`:æ¯”è¾ƒéœ‡è¡ï¼Œå¾—åˆ†ç»å¸¸ä¸‹é™ååˆå¿«é€Ÿä¸Šå‡ã€‚æ¥è¿‘ 20000 æ¬¡ episode æ—¶ï¼Œå¾—åˆ†åœ¨ 5.32 é™„è¿‘ã€‚
  ![](result_img/test_karate_newAction-v1_k=7.jpg)


å®éªŒæµ‹è¯•
- k=1

|         | 0.1    | 0.11666667 | 0.13333333 | 0.15   | 0.16666667 | 0.18333333 | 0.2    | 0.21666667 | 0.23333333 | 0.25   |
| ------- | ------ | ---------- | ---------- | ------ | ---------- | ---------- | ------ | ---------- | ---------- | ------ |
| R nodes | 7.324  | 8.306      | 6.966      | 6.922  | 7.112      | 6.518      | 6.934  | 6.55       | 7.178      | 6.72   |
| T nodes | 19.168 | 18.352     | 20.822     | 22.124 | 21.694     | 23.37      | 22.718 | 23.804     | 23.43      | 24.456 |

- k=3

|         | 0.1   | 0.11666667 | 0.13333333 | 0.15   | 0.16666667 | 0.18333333 | 0.2    | 0.21666667 | 0.23333333 | 0.25   |
| ------- | ----- | ---------- | ---------- | ------ | ---------- | ---------- | ------ | ---------- | ---------- | ------ |
| R nodes | 7.56  | 7.7        | 7.164      | 7.272  | 7.434      | 6.576      | 6.9    | 6.67       | 6.622      | 6.082  |
| T nodes | 19.51 | 19.238     | 20.672     | 21.552 | 21.498     | 22.958     | 22.916 | 23.676     | 23.44      | 24.436 |

- k=5

|         | 0.1    | 0.11666667 | 0.13333333 | 0.15   | 0.16666667 | 0.18333333 | 0.2    | 0.21666667 | 0.23333333 | 0.25   |
| ------- | ------ | ---------- | ---------- | ------ | ---------- | ---------- | ------ | ---------- | ---------- | ------ |
| R nodes | 7.664  | 8.1        | 7.504      | 7.576  | 7.614      | 7.232      | 6.742  | 6.644      | 6.586      | 6.138  |
| T nodes | 19.116 | 18.6       | 20.39      | 20.932 | 20.696     | 21.978     | 22.474 | 23.03      | 22.954     | 23.978 |

- k=7

|         | 0.1    | 0.11666667 | 0.13333333 | 0.15  | 0.16666667 | 0.18333333 | 0.2    | 0.21666667 | 0.23333333 | 0.25  |
| ------- | ------ | ---------- | ---------- | ----- | ---------- | ---------- | ------ | ---------- | ---------- | ----- |
| R nodes | 7.89   | 7.814      | 7.426      | 7.11  | 6.842      | 6.988      | 6.73   | 6.888      | 6.656      | 6.63  |
| T nodes | 18.964 | 19.206     | 20.806     | 22.07 | 21.95      | 22.748     | 22.816 | 23.29      | 23.856     | 24.47 |

- k=10

|         | 0.1    | 0.11666667 | 0.13333333 | 0.15   | 0.16666667 | 0.18333333 | 0.2    | 0.21666667 | 0.23333333 | 0.25   |
| ------- | ------ | ---------- | ---------- | ------ | ---------- | ---------- | ------ | ---------- | ---------- | ------ |
| R nodes | 9.42   | 9.436      | 8.522      | 7.97   | 7.924      | 7.432      | 7.108  | 6.666      | 7.096      | 6.3    |
| T nodes | 13.554 | 13.068     | 15.324     | 18.122 | 18.326     | 20.142     | 20.442 | 22.158     | 21.658     | 23.138 |


å–ä¸åŒ `select_k_Tnodes` çš„å®éªŒç»“æœå¯¹æ¯”å›¾ï¼š

![](result_img/test_karate_newAction-v1_differenet_k.jpg)

- å½“ `k=10` æ—¶ï¼Œæ•ˆæœæ˜¯æ˜æ˜¾ä¸å¥½çš„ï¼›
- å…¶ä»–å–å€¼çš„å®éªŒç»“æœå·®è·ä¸æ˜¯å¾ˆæ˜¾è‘—ï¼Œä½†ç›´è§‰å‘Šè¯‰æˆ‘ï¼Œä¼¼ä¹ `k=3` æ—¶ï¼Œç»¼åˆæ•ˆæœæœ€å¥½ã€‚


**æ¢ç©¶é—®é¢˜**ï¼šdqn ç½‘ç»œçš„é€‰æ‹©ä¸éšæœºé€‰æ‹©æ˜¯å¦æœ‰åŒºåˆ«ï¼Ÿ

å®éªŒç»“æœ
- 3 ç§ç®—æ³•éšæœºé€‰æ‹©

|         | 0.1   | 0.11666667 | 0.13333333 | 0.15   | 0.16666667 | 0.18333333 | 0.2   | 0.21666667 | 0.23333333 | 0.25   |
| ------- | ----- | ---------- | ---------- | ------ | ---------- | ---------- | ----- | ---------- | ---------- | ------ |
| R nodes | 9.272 | 9.076      | 9.494      | 9.476  | 9.302      | 9.134      | 8.912 | 9.19       | 9.318      | 9.312  |
| T nodes | 12.32 | 12.4       | 12.756     | 12.836 | 12.728     | 12.564     | 13.06 | 13.126     | 12.66      | 13.234 |

ç ´æ¡ˆäº†ï¼Œæœ‰å·®åˆ«ï¼Œè€Œä¸”è¿˜å¾ˆå¤§ã€‚


**æ€è€ƒ**ï¼š
1. ç›®å‰è®­ç»ƒçš„ dqn ä¼¼ä¹æ›´å€¾å‘äºé€‰æ‹© `degree` è¿™ä¸ªç®—æ³•ï¼Œæ˜¯å¦æ˜¯å› ä¸ºå…¶ä»– 2 ä¸ªç®—æ³•ç›¸å¯¹è€Œè¨€è·å¾—çš„å¥–åŠ±ä¸æ˜¯å¾ˆå¤§ï¼Ÿ
2. è€ƒè™‘é‡‡ç”¨ `PPO` æ¥æ›¿æ¢ `DQN`

# 2023.10.15

ä½¿ç”¨äº† `PPO` æ¥è®­ç»ƒæ¨¡å‹ï¼Œè®­ç»ƒç»“æœå’Œ `DQN` æ˜¯å·®ä¸å¤šçš„ã€‚

**æ€è€ƒ**ï¼š
1. æ˜¯å¦æ˜¯ action ä¸­ `random` æ‹‰ä½äº†æ€§èƒ½ï¼Ÿ
2. åŸå§‹ç‰ˆæœ¬çš„ `LTTD` environment å¯é€‰æ‹©çš„åŠ¨ä½œä¸ºå›¾ G çš„é¡¶ç‚¹æ•°ï¼Œæ­¤æ—¶å°±ä¼šæœ‰ä¸€ä¸ª `invalid action` çš„é—®é¢˜ï¼Œå³ä¸èƒ½é€‰æ‹©çŠ¶æ€ä¸º `R` or `T` çš„èŠ‚ç‚¹ã€‚
3. environment çš„é€»è¾‘å¯èƒ½éœ€è¦ä¼˜åŒ–æ”¹å–„ã€‚


**å¯¹åŸå§‹ç‰ˆæœ¬çš„ `LTTD` environment (LTTD-v0) è¿›è¡Œäº†æ”¹è¿›**ï¼š
1. åŒæ ·æ˜¯é€‰å–ä¸€ä¸ª action åè¯„ä¼°å¥–åŠ±ï¼Œè¯¥ reward ä¸ºè¯¥ action (node) å¯¹å…¶é‚»å±…èŠ‚ç‚¹çš„å½±å“ $\Delta T - \Delta R$, ä½†ä¸è¿›è¡Œä¼ æ’­ï¼›
2. å½“é€‰å–æœ€åä¸€ä¸ª actionï¼Œå³ç¬¬ `select_k_Tnodes` åï¼Œè¿›è¡Œä¼ æ’­ã€‚ä¼ æ’­ç»“æŸåçš„ reward ä¸º $\frac{|T|-|R|}{\text{select k T nodes}}$, å› ä¸ºæœ€åçš„ reward æ˜¯è¯¥ episode ä¸­æ‰€æœ‰ action å…±åŒè´¡çŒ®çš„ç»“æœï¼Œæ‰€ä»¥å–å¹³å‡å€¼ã€‚**ä¸æ’é™¤åç»­æœ‰æ›´å¥½çš„è®¡ç®—æ–¹æ³•**ã€‚



# 2023.10.16

åœ¨æ›´æ–° `LTTD-v0` åï¼Œå¯¹åŸå§‹ç‰ˆæœ¬çš„ dqn ä¸­ `invalid action` é‡‡å–å±è”½æ“ä½œã€‚

æµ‹è¯•ç»“æœå¦‚ä¸‹ï¼š

- `k=3`

|         | 0.1   | 0.11666667 | 0.13333333 | 0.15   | 0.16666667 | 0.18333333 | 0.2    | 0.21666667 | 0.23333333 | 0.25   |
| ------- | ----- | ---------- | ---------- | ------ | ---------- | ---------- | ------ | ---------- | ---------- | ------ |
| R nodes | 9.932 | 10.294     | 9.068      | 8.412  | 8.698      | 7.778      | 8.112  | 8.478      | 8.114      | 8.132  |
| T nodes | 9.618 | 9.642      | 12.39      | 13.864 | 13.468     | 15.712     | 15.924 | 16.364     | 16.648     | 17.892 |

- `k=5`

|         | 0.1   | 0.11666667 | 0.13333333 | 0.15   | 0.16666667 | 0.18333333 | 0.2    | 0.21666667 | 0.23333333 | 0.25   |
| ------- | ----- | ---------- | ---------- | ------ | ---------- | ---------- | ------ | ---------- | ---------- | ------ |
| R nodes | 7.716 | 7.684      | 8.196      | 7.32   | 7.626      | 7.674      | 8.09   | 7.662      | 7.82       | 7.294  |
| T nodes | 14.39 | 13.976     | 14.8       | 16.416 | 16.17      | 16.012     | 16.104 | 15.824     | 15.842     | 16.462 |


æ•ˆæœæ¯”æœ€åˆå¥½äº†é‚£ä¹ˆä¸€ç‚¹ç‚¹ï¼Œä½†ä¾æ—§å¾ˆå·®ã€‚

è®­ç»ƒç»“æœå’Œä¹‹å‰å·®ä¸å¤šï¼Œloss ä¾æ—§ç¨³å®šä¸Šå‡ï¼Œå¾—åˆ†å°å¹…éœ‡è¡ä¸Šå‡


# 2023.10.17

- æ ¹æ®æ˜¨å¤©ä¿®æ”¹ `LTTD-v0` çš„ reward çš„æ€è·¯ï¼Œä¿®æ”¹ä¸€ä¸‹ `LTTD-v1` çš„ rewardã€‚
  çœæµï¼šæ²¡å•¥æ˜¾è‘—å˜åŒ–
- å°† `LTTD-v1` çš„ `random` è¿™ä¸ª action å»é™¤ï¼š
  å†æ¬¡çœæµï¼šæ²¡å•¥æ˜¾è‘—å˜åŒ–ï¼Œä¾æ—§æ¥è¿‘ degree çš„ç®—æ³•ã€‚

ä¿®æ”¹ `LTTD-v1` reward è®¡ç®—æ–¹å¼ï¼Œæé«˜çº æ­£ R node çš„å¾—åˆ†:

è®¡ç®— $\Delta T$ å’Œ $\Delta R$, å¦‚æœ $\Delta R <0$, åˆ™ $\Delta R = \alpha \times \Delta R$, $\alpha>0$.

$$
reward = \begin{cases}
  \frac{\Delta T - \Delta R}{\text{budget k}}, & \Delta R >0 \\
  \frac{\Delta T - \alpha\times\Delta R}{\text{budget k}}, & \Delta R <0 
\end{cases}
$$

è®­ç»ƒæ—¶ k=3.
- $\alpha=1.5$. çœæµï¼šå’Œä¹‹å‰å·®ä¸å¤šã€‚
- $\alpha=3$. åŒä¸Šã€‚


è®­ç»ƒæ—¶ k=8.
- $\alpha=1.5$. çœæµï¼šå’Œä¹‹å‰å·®ä¸å¤šã€‚
- $\alpha=3$. åŒä¸Šã€‚


**æ€è€ƒ**ï¼š
1. æ˜¯å¦æ˜¯ karate club çš„è§„æ¨¡å¤ªå°ï¼Ÿè€ƒè™‘å¯¹å¤šä¸ªæ•°æ®é›†è¿›è¡Œæµ‹è¯•ã€‚
2. ç›®å‰å¯ä»¥ç¡®å®šçš„ä¸€ä¸ªç°è±¡æ˜¯ï¼Œè®­ç»ƒæ—¶ï¼Œ*k çš„å–å€¼ä¸ç”¨å¤ªå¤§*ã€‚è€ƒè™‘åœ¨ç½‘ç»œä¸­åŠ å…¥ `dropout` å±‚ã€‚



# 2023.10.18

åŠ ä¸Š `Dropout` å±‚ï¼š
```
Net_Karate(
  (flatten): Flatten(start_dim=1, end_dim=-1)
  (lin_relu): Sequential(
    (0): Linear(in_features=34, out_features=64, bias=True)
    (1): ReLU()
    (2): Dropout(p=0.2, inplace=False)
    (3): Linear(in_features=64, out_features=32, bias=True)
    (4): ReLU()
    (5): Linear(in_features=32, out_features=2, bias=True)
  )
)
```
å¯¹äº `LTTD-v1`

- ä¿®æ”¹å¥–åŠ±å‡½æ•°ï¼š

  å½“é€‰å–æŸä¸ª action(node) æ—¶ï¼Œé¢„ä¼°å…¶å‘¨å›´é‚»å±…èŠ‚ç‚¹çš„çŠ¶å†µï¼Œå½“å¯èƒ½å˜ä¸º `T-active` æ—¶ï¼Œ$\Delta T+1$;
  å½“å¯èƒ½å°† `R-active` è½¬æ¢ä¸º `T-active` æ—¶ï¼Œ$\Delta R-1$.

  å¦‚æœ action çš„é‚»å±…æ²¡æœ‰ `R-active` nodesï¼Œåˆ™ $\Delta T = 0.5\Delta T$;
  è‹¥æœ‰ï¼Œåˆ™ $\Delta R = \text{num-of-R-nbr}\times (\Delta R -1)$.

  ç»è¿‡ä¿®æ­£åï¼Œ
  $$
  reward = \Delta T - \Delta R
  $$

- å°† action ä¸­çš„ `random` æ›¿æ¢ä¸º `contrid`

æµ‹è¯•ç»“æœï¼šæ— æ˜¾è‘—å˜åŒ–ï¼Œæ¢æˆ `contrid` åæ•ˆæœè¿›ä¸€æ­¥ä¸‹é™ã€‚ğŸ¤¡ğŸ˜­


å¯¹äº `LTTD-v0`ï¼š

- ä¿®æ”¹å¥–åŠ±å‡½æ•°ï¼š
  $$
  reward = \begin{cases}
  1, &\text{spread done and } T\ge R \\
  -1, &\text{spread done and } T< R \\
  0, &\text{spreading}
  \end{cases}
  $$
- target net æ¯ 100 æ¬¡ episode åè¿›è¡Œæ›´æ–°ï¼Œè€Œä¸æ˜¯æ¯æ¬¡ episode åè¿›è¡Œå¾®è°ƒ
- batch size å¢å¤§è‡³ 256
- è¶…å‚æ•°ï¼š
  - GAMMA = 0.6
  - EPS_START = 0.9
  - EPS_END = 0.05
  - EPS_DECAY = 10000

æ•ˆæœï¼š
- loss å¯ä»¥ç¨³å®šä¸‹é™äº†
- å½“ k è¾ƒå°æ—¶ï¼Œç»è¿‡ 100,000 æ¬¡è®­ç»ƒï¼Œæ•ˆæœä¾æ—§éå¸¸å·®ã€‚
- å½“ k=8 æ—¶ï¼Œè®­ç»ƒæ•ˆæœå¥½äº†é‚£ä¹ˆä¸€ä¸ç‚¹. loss ç¨³å®šä¸‹é™ï¼Œå¾—åˆ†ä¸Šå‡ï¼Œä½†å¾ˆæ…¢ã€‚
  ![](result_img/test_karate_v0_k=8.jpg)
  æµ‹è¯•ç»“æœï¼šå¾ˆä¸€èˆ¬ï¼Œä¸æ˜¯å¾ˆç†æƒ³ã€‚

  |         | 0.1   | 0.11666667 | 0.13333333 | 0.15   | 0.16666667 | 0.18333333 | 0.2    | 0.21666667 | 0.23333333 | 0.25  |
  | ------- | ----- | ---------- | ---------- | ------ | ---------- | ---------- | ------ | ---------- | ---------- | ----- |
  | R nodes | 9.952 | 10.714     | 9.688      | 8.346  | 9.008      | 8.382      | 8.23   | 8.098      | 8.212      | 7.038 |
  | T nodes | 9.526 | 9.75       | 12.104     | 14.694 | 14.6       | 16.746     | 17.488 | 18.668     | 18.488     | 19.84 |

- k=5. å°†å­¦ä¹ ç‡è°ƒæ•´ä¸º $10^{-3}$

  æµ‹è¯•ç»“æœï¼šæ•ˆæœåˆå¥½èµ·æ¥äº†?

  |         | 0.1    | 0.11666667 | 0.13333333 | 0.15   | 0.16666667 | 0.18333333 | 0.2    | 0.21666667 | 0.23333333 | 0.25   |
  | ------- | ------ | ---------- | ---------- | ------ | ---------- | ---------- | ------ | ---------- | ---------- | ------ |
  | R nodes | 8.416  | 7.918      | 7.684      | 6.758  | 7.192      | 7.186      | 6.82   | 6.902      | 6.602      | 6.76   |
  | T nodes | 16.986 | 18.16      | 19.532     | 20.096 | 20.688     | 20.992     | 22.222 | 22.224     | 23.208     | 23.204 |

- k=3. å­¦ä¹ ç‡ç­‰åŒäº k=5. 80,000 episodes è€—æ—¶ 40mã€‚
  æµ‹è¯•ç»“æœï¼šå±…ç„¶æ¥è¿‘ `LTTD-v1` çš„æ•ˆæœï¼

  |         | 0.1    | 0.11666667 | 0.13333333 | 0.15   | 0.16666667 | 0.18333333 | 0.2    | 0.21666667 | 0.23333333 | 0.25   |
  | ------- | ------ | ---------- | ---------- | ------ | ---------- | ---------- | ------ | ---------- | ---------- | ------ |
  | R nodes | 7.29   | 7.54       | 7.274      | 6.964  | 6.492      | 6.728      | 6.766  | 6.442      | 6.366      | 6.416  |
  | T nodes | 19.826 | 20.776     | 21.976     | 22.352 | 23.132     | 23.218     | 23.454 | 23.864     | 24.284     | 24.326 |

**è¿‘æœŸå®éªŒæ€»ç»“ï¼š**
å¯¹äº karate ç½‘ç»œ
1. æ€»ä½“è€Œè¨€ï¼Œk å€¼ä¸éœ€è¦å¤ªå¤§ã€‚
2. `LTTD-v0` çš„è®­ç»ƒæ—¶é•¿æ¯”è¾ƒé•¿ï¼Œloss ä¸ä¸€å®šèƒ½ç¨³å®šä¸‹é™ï¼Œä½†æœ€è¿‘å‡ æ¬¡éƒ½èƒ½ç¨³å®šä¸‹é™ï¼Œä¸”æ•ˆæœæœ‰æå‡ï¼Œååˆ†æ¥è¿‘ `degree` ç®—æ³•ã€‚
3. `LTTD-v1` çš„è®­ç»ƒæ—¶é•¿ç›¸å¯¹å¿«ä¸€äº›ï¼Œloss å¯ä»¥ç¨³å®šä¸‹é™ï¼Œæµ‹è¯•æ•ˆæœé€šå¸¸æŒå¹³ `degree` ç®—æ³•ã€‚


# 2023.10.21

- ç›®æ ‡ç½‘ç»œ dolphins
- dqn ç»“æ„
  ```
      Net_Dolphin(
      (lin_relu): Sequential(
        (0): Linear(in_features=62, out_features=64, bias=True)
        (1): ReLU()
        (2): Linear(in_features=64, out_features=64, bias=True)
        (3): ReLU()
        (4): Linear(in_features=64, out_features=62, bias=True)
      )
    )
  ```
- è¶…å‚æ•°ï¼š
  - BATCH_SIZE_DOL = 256
  - LEARNING_RATE_DOL = 1e-3
  - MAX_MEMORY_CAPACITY = 30000
  - GATHER_EXPERIENCE_SIZE = 100
  - TARGET_REPLACE_ITER = 200
  - TAU = 0.005
  - GAMMA = 0.6
  - EPS_START = 0.9
  - EPS_END = 0.05
  - EPS_DECAY = 10000


> k = 8
è®­ç»ƒç»“æœï¼š

![](result_img/dolphins_v0_k=8.jpg)

æµ‹è¯•æ•ˆæœï¼š

|         | 0.1    | 0.11666667 | 0.13333333 | 0.15   | 0.16666667 | 0.18333333 | 0.2    | 0.21666667 | 0.23333333 | 0.25   |
| ------- | ------ | ---------- | ---------- | ------ | ---------- | ---------- | ------ | ---------- | ---------- | ------ |
| R nodes | 13.686 | 13.27      | 12.51      | 12.338 | 11.842     | 11.462     | 11.692 | 11.308     | 11.06      | 10.844 |
| T nodes | 25.298 | 27.748     | 30.788     | 32.944 | 34.148     | 35.422     | 37.06  | 38.464     | 39.168     | 41.366 |

ä¼ ç»Ÿç®—æ³•ï¼š
final R nodes
|         | 0.1    | 0.11666667 | 0.13333333 | 0.15   | 0.16666667 | 0.18333333 | 0.2    | 0.21666667 | 0.23333333 | 0.25   |
| ------- | ------ | ---------- | ---------- | ------ | ---------- | ---------- | ------ | ---------- | ---------- | ------ |
| Degree  | 12.938 | 12.318     | 12.372     | 11.716 | 11.616     | 11.314     | 10.876 | 11.004     | 10.844     | 10.576 |
| ContrId | 12.576 | 11.988     | 11.61      | 11.361 | 11.306     | 10.996     | 10.706 | 10.562     | 10.364     | 10.21  |
| TCS     | 16.338 | 16.516     | 15.632     | 14.852 | 15.08      | 14.292     | 14.436 | 13.498     | 13.33      | 13.006 |
| Greedy  | 9.65   | 9.588      | 8.624      | 8.822  | 8.644      | 8.284      | 8.856  | 8.358      | 8.754      | 8.506  |
| M3T     | 12.504 | 12.15      | 11.604     | 11.131 | 10.444     | 10.072     | 9.791  | 9.61       | 9.462      | 9.422  |

å¯¹æ¯”å›¾ï¼š

![](result_img/cmp_dolphin_v0.jpg)

æ€»ä½“å¤„äºä¸­é—´æ°´å¹³ã€‚

# 2023.10.22

å¥–åŠ±å‡½æ•°æ˜¯æœ‰å½±å“çš„ï¼Œä¹‹å‰å†™çš„æµ‹è¯•å‡½æ•°å¯èƒ½æœ‰é—®é¢˜ï¼Œå¯¼è‡´ç»“æœå¾ˆå·®(æ¼ğŸ˜¡)

è°ƒæ•´åçš„ç»“æœï¼š

|         | 0.1    | 0.11666667 | 0.13333333 | 0.15   | 0.16666667 | 0.18333333 | 0.2    | 0.21666667 | 0.23333333 | 0.25   |
| ------- | ------ | ---------- | ---------- | ------ | ---------- | ---------- | ------ | ---------- | ---------- | ------ |
| R nodes | 13.364 | 12.526     | 12.182     | 11.578 | 11.604     | 11.274     | 11.256 | 11.132     | 10.82      | 10.494 |
| T nodes | 26.706 | 28.336     | 31.55      | 33.392 | 34.976     | 36.16      | 37.6   | 39.168     | 40.408     | 42.744 |

å¥½å§ï¼Œæœ‰ï¼Œä½†ä¸å¤§ã€‚

# 2023.10.26

ç»è¿‡ GAE å¾—åˆ° embeddings åå†è¾“å…¥ DQNã€‚çœæµï¼šåœ¨ karate çš„æµ‹è¯•ä¸­ï¼Œæœ€ç»ˆæ•ˆæœå˜åŒ–ä¸å¤§ã€‚

# 2023.10.27

æ–°æ€è·¯ï¼š
1. æ ¹æ® GraphSage çš„æ€æƒ³ï¼Œèšåˆ inactive èŠ‚ç‚¹å‘¨å›´ T,R èŠ‚ç‚¹çš„ä¿¡æ¯ï¼Œèµ‹å€¼ç»™ inactive èŠ‚ç‚¹ï¼Œæ ¹æ®å€¼å¯¹èŠ‚ç‚¹è¿›è¡Œé€‰å–ã€‚
2. è®­ç»ƒ DQN åªç”¨äºå¯»æ‰¾èƒ½å¤Ÿä½¿å¾— T å½±å“åŠ›æœ€å¤§çš„èŠ‚ç‚¹ã€‚


# 2023.10.29

å®éªŒå¯¹è±¡ï¼šfood
å‚æ•°è®¾ç½®ï¼š
- BATCH_SIZE_FB = 64
- LEARNING_RATE_FB = 1e-4
- MAX_MEMORY_CAPACITY = 100,000
- GATHER_EXPERIENCE_SIZE = 100
- TARGET_REPLACE_ITER = 200
- TAU = 0.005
- EPS_DECAY = 30000
- episode = 100,000
- k=20

è®­ç»ƒç»“æœï¼š

![](result_img/food_v0_k=20.jpg)

æµ‹è¯•ç»“æœ

![](result_img/cmp_food_v0.jpg)

å…·ä½“æ•°æ®ï¼š

|         | 0.01    | 0.014   | 0.018   | 0.023   | 0.0278  | 0.032   | 0.036   | 0.041   | 0.045   | 0.05    |
| ------- | ------- | ------- | ------- | ------- | ------- | ------- | ------- | ------- | ------- | ------- |
| R nodes | 144.708 | 141.114 | 140.486 | 137.444 | 125.302 | 128.31  | 125.342 | 120.09  | 117.238 | 115.868 |
| T nodes | 79.738  | 106.49  | 133.358 | 145.378 | 162.998 | 172.838 | 185.34  | 195.158 | 201.244 | 212.552 |

DQN ä¼¼ä¹è¿˜æ˜¯åå‘å»æ‰©æ•£ Tï¼Œå¿½ç•¥äº† R çš„éåˆ¶ã€‚æ€»ä½“æ°´å¹³æ˜¯ä¸­ç­‰ã€‚å¾—æƒ³åŠæ³•å¼•å¯¼ DQN å»é™åˆ¶ R çš„ä¼ æ’­ã€‚


å¤§è‡´ä¼°ç®—äº†ä¸€ä¸‹ï¼ŒDQN è‹¥è¦è¶…è¿‡å…¶ä»–ç®—æ³•ï¼Œè‡³å°‘éœ€è¦ï¼š

final_R_recv:
- dolphin: 15% ~ 20%.
- food: 14% ~ 24%.
- netsci: 10% ~ 15%.
- uspower: 11% ~ 16%.

final_T_revc:
- dolphin: 46% ~ 66%.
- food: 19% ~ 38%.
- netsci: 5% ~ 19%.
- uspower: 9% ~ 30%.

å¦‚æœè€ƒè™‘ R seed å’Œ budget k:
dolphins: seed R rate 10%, budget k rate 10% ~ 25%.
other: seed R rate 5%, budget k rate 1% ~ 5%

$$
\text{å¹³å‡å€¼} = \frac{\text{final T or R recv}}{\text{R seed rate}*\text{budget k}}
$$

åˆ™
final_R_recv:
- dolphin: 6 ~ 20
- food: 60 ~ 481
- netsci: 43 ~ 307
- uspower: 45 ~ 333

final_T_recv:
- dolphin: 26.4 ~ 46
- food: 152 ~ 380
- netsci: 76 ~ 100
- uspower: 120 ~ 180


# 2023.11.1

æˆ–è®¸è®­ç»ƒæ—¶ï¼Œå°† LTTD çš„é˜ˆå€¼å›ºå®šä½ï¼Œå³ reset æ—¶ä¸é‡ç½®è¿™äº›é˜ˆå€¼ï¼Œæ˜¯å¦ä¼šæ›´å®¹æ˜“ç‚¹ï¼Ÿ

# 2023.11.2

ä¿®æ”¹äº† lttd çš„ reward_shapingï¼š
- æ¯æ¬¡é€‰æ‹©æ—¶ï¼Œå°†å¤§è‡´è¯„ä¼° action é€‰å–åçš„ä¼ æ’­æ•ˆæœï¼Œç»Ÿè®¡ delta_T å’Œ delta_R çš„å˜åŒ–ï¼Œreward=delta_T-delta_R
- æœ€åä¸€ä¸ª action æ—¶ï¼Œreward=delta_T-delta_Rï¼Œå½“
  - RN_rate <= target_to_reach æ—¶ï¼Œreward*=1.5.
  - TR_rate >= 5 æ—¶ï¼Œreward*=1.5
  - TR_rate >= 2 æ—¶ï¼Œreward*=1.1

ä¿®æ”¹äº† DQN çš„ GAMMA å€¼ï¼Œä» 0.6 é™è‡³ 0.55

ç»è¿‡20000æ¬¡ episode è®­ç»ƒåè¿›è¡Œæµ‹è¯•ï¼š

|         | 0.1    | 0.11666667 | 0.13333333 | 0.15   | 0.16666667 | 0.18333333 | 0.2    | 0.21666667 | 0.23333333 | 0.25   |
| ------- | ------ | ---------- | ---------- | ------ | ---------- | ---------- | ------ | ---------- | ---------- | ------ |
| R nodes | 12.616 | 12.708     | 12.308     | 12.042 | 11.678     | 11.37      | 11.092 | 11.154     | 10.68      | 10.478 |
| T nodes | 29.294 | 30.444     | 32.212     | 34.616 | 35.942     | 37.908     | 38.38  | 39.472     | 40.787     | 42.744 |

å¥½äº†é‚£ä¹ˆä¸€ä¸¢ä¸¢, ä½†æ²¡å‘ç”Ÿè´¨å˜ã€‚

![](result_img/cmp_dolphin_v0_1.jpg)

# 2023.11.4

ä¹‹å‰è®­ç»ƒæ—¶ï¼Œdolphins çš„è®­ç»ƒå‚æ•°è®¾ç½®é”™è¯¯ï¼Œå°† au_T_rate è®¾ç½®æˆ 0.01ï¼Œè€Œæµ‹è¯•æ—¶çš„ au_T_rate ä¸º 0.08ï¼Œå› æ­¤æ•ˆæœæœ‰äº›é—®é¢˜ã€‚ç›®å‰å·²ä¿®æ­£ã€‚

ä½¿ç”¨ vector environmentï¼Œæ¯ä¸ª env è®¾ç½®ä¸åŒå‚æ•°ã€‚
ä½¿ç”¨ A2C è¿›è¡Œè®­ç»ƒã€‚

å‚æ•°è®¾ç½®ï¼š

dolphin ç½‘ç»œ

ç¯å¢ƒå‚æ•°ï¼š
- n_envs = 3
- n_updates = 1000 # å¯¹ actorï¼Œcritic ç½‘ç»œè¿›è¡Œæ›´æ–°çš„æ¬¡æ•°
- n_steps_per_update = 128 # åœ¨æ¯æ¬¡æ›´æ–°å‰è¿›è¡Œï¼Œéœ€è¦ play çš„æ¬¡æ•°

```python
envs = gym.vector.AsyncVectorEnv(
    [
        lambda: gym.make(
            'LTTD-v0',
            G=G1,
            init_rumor_rate=0.1,
            au_T_rate=0.08,
            k_budget=0.10,
            target_to_reach=0.155,
        ),
        lambda: gym.make(
            'LTTD-v0',
            G=G1,
            init_rumor_rate=0.1,
            au_T_rate=0.08,
            k_budget=0.15,
            target_to_reach=0.147,
        ),
        lambda: gym.make(
            'LTTD-v0',
            G=G1,
            init_rumor_rate=0.1,
            au_T_rate=0.08,
            k_budget=0.25,
            target_to_reach=0.137,
        ),
    ]
)
```

agent hyperparamsï¼š
- gamma = 0.6 # è¿™ä¸ªå€¼è·Ÿ DQN ä¸­çš„ gamma æ˜¯åŒä¸€ä¸ªï¼Œå¤ªå¤§ loss ä¸å®¹æ˜“æ”¶æ•›
- lam = 0.95  # hyperparameter for GAE
- ent_coef = 0.01  # coefficient for the entropy bonus (to encourage exploration)
- actor_lr = 0.001
- critic_lr = 0.005

è®­ç»ƒç»“æœ

![](result_img/dolphin_a2c_v0_vec_env3_1.png)

è¿™ä¸ª return çœ‹èµ·æ¥ä¸æ˜¯å¾ˆæ˜æ˜¾ï¼Œä½†æ˜¯ loss éƒ½æ˜¯ç¨³å®šä¸‹é™çš„ã€‚

æµ‹è¯•ç»“æœï¼š

|         | 0.1    | 0.11666667 | 0.13333333 | 0.15   | 0.16666667 | 0.18333333 | 0.2    | 0.21666667 | 0.23333333 | 0.25   |
| ------- | ------ | ---------- | ---------- | ------ | ---------- | ---------- | ------ | ---------- | ---------- | ------ |
| R nodes | 12.874 | 12.746     | 12.008     | 11.958 | 11.428     | 11.488     | 10.898 | 10.994     | 10.46      | 10.362 |
| T nodes | 29.594 | 31.752     | 34.354     | 36.556 | 38.476     | 40.128     | 40.876 | 42.26      | 43.462     | 44.808 |

T nodes çš„æ•°é‡æå‡å¾ˆæ˜æ˜¾ã€‚


# 2023.11.12

æŠ˜è…¾äº†å¥½å‡ å¤©ï¼Œè¿™ä¸ª `n_step_update` éœ€è¦å¤§ä¸€ç‚¹ï¼Œæ¯”å¦‚ 128ï¼Œè®­ç»ƒç»“æœä¼šæ¯”è¾ƒç¨³å®šã€‚å¦‚æœå¤ªå° `Critic loss` éœ‡è¡çš„å¾ˆå‰§çƒˆã€‚

ä½†æ˜¯è®­ç»ƒçš„å°±æ¯”è¾ƒæ…¢ã€‚

# 2023.11.16

è®­ç»ƒ A2C éœ€è¦è¿æ°”ï¼Œå¯¹åˆå§‹å‚æ•°ååˆ†æ•æ„Ÿã€‚ä¸ä¸€å®šèƒ½å¤ç°ä¹‹å‰çš„æ•ˆæœã€‚

# 2023.11.21

å½“æ—¶åœ¨ A2C ä¸­æ·»åŠ äº† `initialize()`ï¼Œç”»è›‡æ·»è¶³ï¼Œæå¾—ç®—æ³•æ•ˆæœå¾ˆå·®ã€‚

# 2023.12.19

åˆé‡æ–°çœ‹äº†ä¸€ä¸‹ DQN çš„ä»£ç ï¼Œå…¶ä¸­ `target_net` åœ¨é€‰æ‹© max Q value æ—¶ï¼Œæ²¡æœ‰è€ƒè™‘valid action çš„é—®é¢˜ï¼Œè¿™ä¼šä¸ä¼šå¯¹è®­ç»ƒç»“æœé€ æˆå½±å“ï¼Ÿ

# 2023.12.20

å¤§è‡´å®ç°äº† embedding+DQN çš„ç»“æ„ã€‚ä½†æ˜¯åœ¨æ›´æ–° node embedding æ—¶ï¼Œç”±äºéœ€è¦ $\sum_{u\in N(v)}x_u^t$ ï¼Œå¤šæ¬¡è¿™æ ·æ“ä½œåå¾—åˆ°çš„ embedding å°†ä¼šæº¢å‡ºã€‚

# 2023.12.20

`loss.backward()` æ—¶å‡ºç°æŠ¥é”™ "Trying to backward through the graph a second time...". åŸå› æ˜¯ä»£ç ä¸­çš„æœ‰äº›æ“ä½œæ˜¯ inplace ï¼Œæ¯”å¦‚ä»æŸä¸ª tensor ä¸­å–å‡ºæŸä¸€ç»´ï¼Œå¦‚æœä¿®æ”¹äº†è¿™å–å‡ºçš„ä¸€ç»´ä¸­çš„å…ƒç´ ï¼Œå°±æ˜¯ä¸€ä¸ª inplace æ“ä½œã€‚

# 2023.12.23

ä½†ç»è¿‡å¤šå¤©æ’æŸ¥ï¼Œä»£ç ä¸­å¹¶æ²¡æœ‰ inplace çš„æ“ä½œã€‚é€šè¿‡ [pytorch forum](https://discuss.pytorch.org/t/runtimeerror-one-of-the-variables-needed-for-gradient-computation-has-been-modified-by-an-inplace-operation-code-worked-in-pytorch-1-2-but-not-in-1-5-after-updating/87327) ä¸­çš„è§£é‡Šï¼Œä¼˜åŒ–å™¨çš„ `.step()` å¯¹æƒé‡çš„æ”¹å˜æ˜¯ inplace çš„ã€‚

è¿™ä¹Ÿå°±è§£é‡Šäº†ä¸ºä»€ä¹ˆç¬¬ä¸€æ¬¡ `backward` æ˜¯æˆåŠŸçš„ï¼Œè€Œç¬¬äºŒæ¬¡ `backward` å°±ä¼šæŠ›å‡º "RuntimeError: one of the variables needed for gradient computation has been modified by an inplace operation" é”™è¯¯ã€‚

# 2023.12.26

ä¸æŒ‰ä¹‹å‰çš„æ–¹å¼äº†ï¼Œæ¢ä¸ªæ€è·¯ï¼Œæ”¶é›†å®Œ experience ä¹‹åï¼Œåœ¨ learn ä¹‹æ—¶å†è½¬æ¢ä¸ºå¯¹åº”çš„ embeddingã€‚

å·²ç»è®­ç»ƒå®Œ dolphin è¿™ä¸ªæ•°æ®é›†äº†ã€‚ 

å‚æ•°è®¾ç½®:
- BATCH_SIZE_DOL = 64
- NODE_NUM_DOL = G1.number_of_nodes()
- EPS_DECAY_DOL = 10000
- EPS_START_DOL = 0.99
- EPS_END_DOL = 0.05
- GAMMA_DOL = 0.9
- LEARNING_RATE_DOL = 1e-3
- MAX_MEMORY_CAPACITY = 10000
- embedding_dim = 32



ç»“æœå¦‚ä¸‹:



|         | 0.1   | 0.116  | 0.133  | 0.15   | 0.166 | 0.183  | 0.2    | 0.216  | 0.233  | 0.25   |
| ------- | ----- | ------ | ------ | ------ | ----- | ------ | ------ | ------ | ------ | ------ |
| R nodes | 10.886 | 10.712 | 10.396 | 10.056 | 9.452 | 9.354  | 9.188  | 9.132  | 9.006   | 8.668  |
| T nodes | 31.86 | 33.312 | 36.256 | 38.798 | 40.012 | 41.872 | 43.018 | 44.158 | 45.338 | 46.846 |

å·²ç»è¶…è¿‡ `M3T`ï¼Œé¢†å…ˆäº DQN å’Œ A2C äº†ï¼Œå¹¶ä¸”åœ¨ R_nodes æ•°é‡ä¸ŠåŸºæœ¬æŒå¹³äº greedy ç®—æ³• (å–œğŸ˜)
ä¼ æ’­çœŸç›¸çš„èƒ½åŠ›ä»…æ¬¡äº greedyã€‚